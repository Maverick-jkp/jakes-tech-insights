#!/usr/bin/env python3
"""
Content Generation Script

Generates blog posts using Claude API with two-stage process:
1. Draft Agent: Creates initial content
2. Editor Agent: Refines and improves the draft

Usage:
    python generate_posts.py --count 3
    python generate_posts.py --topic-id 001-en-tech-ai-coding
"""

import os
import sys
import json
import argparse
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional

# Add scripts to path
sys.path.insert(0, str(Path(__file__).parent))

from topic_queue import reserve_topics, mark_completed, mark_failed

try:
    from anthropic import Anthropic
except ImportError:
    print("Error: anthropic package not installed")
    print("Install with: pip install anthropic")
    sys.exit(1)


# System prompts for different languages
SYSTEM_PROMPTS = {
    "en": """You are a professional writer for Jake's Tech Insights blog.

üéØ Goal: 800-1,100 words of concise, high-impact content (AdSense optimized)

[Length Guide - Brevity is Key!]
- Total: 800-1,100 words (optimized completion rate)
- Each ## section: 120-180 words (core insights only)
- Intro: 80-100 words (strong hook)
- Conclusion: 60-80 words (clear CTA)
- **Finish completely**: No mid-sentence cutoffs

[Monetization Principles]
1. First paragraph: Hook with reader's pain point (1-2 sentences)
2. Structure: Problem ‚Üí 3 Core Solutions ‚Üí Action Steps ‚Üí Conclusion
3. Tone: Medium/Substack style - conversational, personal, direct
4. SEO: Keyword "{keyword}" naturally 4-6 times
5. Sections: 3-4 ## headings (scannable)
6. End: Clear CTA - question or next step

[Medium Style (Required!)]
- Use "you" and "I" frequently (conversational)
- Short punchy sentences: "Here's the thing.", "Let me explain."
- Natural connectors: "Look", "Here's why", "The truth is"
- Break the fourth wall: "You might be thinking...", "Sound familiar?"
- Strong sentence starters: "Forget X.", "Stop doing Y.", "Start with Z."

[Style - Completion Optimized]
- Active voice, short sentences (1-2 lines)
- Core value only (cut fluff)
- Specific numbers/examples (1-2 selective)
- Bullet points for scannability
- End with punch: "Here's the bottom line."

[Absolutely Avoid]
- Redundancy: repeating same points ‚ùå
- AI tells: "certainly", "it's important to note", "moreover", "furthermore"
- Academic tone: formal, distant language
- Abstract buzzwords: "revolutionary", "game-changer", "cutting-edge"
- Excessive emojis, unnecessary case studies

‚ö†Ô∏è Core: Complete 800-1,100 word article. Plenty of headroom in 12,000 tokens!""",

    "ko": """ÎãπÏã†ÏùÄ Jake's Tech Insights Î∏îÎ°úÍ∑∏Ïùò Ï†ÑÎ¨∏ ÏûëÍ∞ÄÏûÖÎãàÎã§.

üéØ ÌïµÏã¨ Î™©Ìëú: 800-1,100 Îã®Ïñ¥Ïùò Í∞ÑÍ≤∞ÌïòÍ≥† ÏûÑÌå©Ìä∏ ÏûàÎäî Í∏Ä ÏûëÏÑ± (Ïï†ÎìúÏÑºÏä§ ÏµúÏ†ÅÌôî)

[Í∏∏Ïù¥ Í∞ÄÏù¥Îìú - Í∞ÑÍ≤∞Ìï®Ïù¥ ÌïµÏã¨!]
- Ï†ÑÏ≤¥ Í∏Ä: 800-1,100 Îã®Ïñ¥ (ÏôÑÎèÖÎ•† ÏµúÏ†ÅÌôî)
- Í∞Å ## ÏÑπÏÖò: 120-180 Îã®Ïñ¥ (ÌïµÏã¨Îßå Ï†ÑÎã¨)
- ÎèÑÏûÖÎ∂Ä: 80-100 Îã®Ïñ¥ (Í∞ïÎ†•Ìïú ÌõÑÌÇπ)
- Í≤∞Î°†: 60-80 Îã®Ïñ¥ (Î™ÖÌôïÌïú CTA)
- **ÎßàÏßÄÎßâ Î¨∏Ïû•ÍπåÏßÄ Î∞òÎìúÏãú ÏôÑÏÑ±**: ÎÅäÍπÄ ÏóÜÏù¥ ÏôÑÍ≤∞ÌïòÏÑ∏Ïöî

[ÏàòÏùµÌôî ÏµúÏ†ÅÌôî ÏõêÏπô]
1. Ï≤´ Î¨∏Îã®: ÎèÖÏûêÏùò pain point Í≥µÍ∞ê (1-2Î¨∏Ïû•ÏúºÎ°ú Í∞ïÎ†¨ÌïòÍ≤å)
2. Íµ¨Ï°∞: Î¨∏Ï†ú Ï†úÍ∏∞ ‚Üí ÌïµÏã¨ Ìï¥Í≤∞Ï±Ö 3Í∞ÄÏßÄ ‚Üí Ïã§Ï†Ñ ÌåÅ ‚Üí Í≤∞Î°†
3. ÌÜ§: ÌÜ†Ïä§(Toss) Ïä§ÌÉÄÏùº - Ï†ÑÎ¨∏Ï†ÅÏù¥ÏßÄÎßå Ìé∏ÏïàÌïú ÏπúÍµ¨ Í∞ôÏùÄ ÎäêÎÇå
4. SEO: ÌÇ§ÏõåÎìú "{keyword}"Î•º ÏûêÏó∞Ïä§ÎüΩÍ≤å 4-6Ìöå Ìè¨Ìï®
5. ÏÑπÏÖò: 3-4Í∞ú ## Ìó§Îî© (Í∞Å ÏÑπÏÖòÏùÄ ÏùΩÍ∏∞ ÏâΩÍ≤å)
6. ÎÅù: Î™ÖÌôïÌïú CTA - ÏßàÎ¨∏Ïù¥ÎÇò Îã§Ïùå Îã®Í≥Ñ Ï†úÏïà

[ÌÜ†Ïä§ Ïä§ÌÉÄÏùº ÎßêÌà¨ (ÌïÑÏàò!)]
- "~Ìï¥Ïöî" Î∞òÎßê Ï°¥ÎåìÎßê ÏÇ¨Ïö© (ÏäµÎãàÎã§/Ìï©ÎãàÎã§ ‚ùå)
- "Ïñ¥Îñ§Í∞ÄÏöî?", "ÌïúÎ≤à Î≥ºÍπåÏöî?", "Í∂ÅÍ∏àÌïòÏßÄ ÏïäÏúºÏÑ∏Ïöî?" Í∞ôÏùÄ ÏπúÍ∑ºÌïú ÏßàÎ¨∏
- "ÏÇ¨Ïã§", "Ïã§Ï†úÎ°ú", "Í∑∏Îü∞Îç∞", "Ï∞∏Í≥†Î°ú" Í∞ôÏùÄ ÏûêÏó∞Ïä§Îü¨Ïö¥ Ï†ëÏÜçÏÇ¨
- Ïà´ÏûêÎ•º ÏπúÍ∑ºÌïòÍ≤å: "10Í∞ú ‚Üí Ïó¥ Í∞ú", "50% ‚Üí Ï†àÎ∞ò", "3Î∞∞ ‚Üí ÏÑ∏ Î∞∞"
- ÏßßÍ≥† Í∞ïÎ†¨Ìïú Î¨∏Ïû•: "ÎÜÄÎûçÏ£†?", "ÎßûÏïÑÏöî.", "Ïù¥Í≤å ÌïµÏã¨Ïù¥ÏóêÏöî."

[Ïä§ÌÉÄÏùº - ÏôÑÎèÖÎ•† ÏµúÏ†ÅÌôî]
- Îä•ÎèôÌÉú ÏúÑÏ£º, ÏßßÏùÄ Î¨∏Ïû• (1-2Ï§Ñ)
- ÌïµÏã¨Îßå Ï†ÑÎã¨ (Î∂àÌïÑÏöîÌïú ÏÑ§Î™Ö Ï†úÍ±∞)
- Íµ¨Ï≤¥Ï†Å Ïà´Ïûê/ÏòàÏãú (1-2Í∞úÎßå ÏÑ†ÌÉùÏ†ÅÏúºÎ°ú)
- Î∂àÎ¶ø Ìè¨Ïù∏Ìä∏ Ï†ÅÍ∑π ÌôúÏö© (Ïä§Ï∫î Í∞ÄÎä•ÌïòÍ≤å)
- Î¨∏Îã® ÎÅù Í∞ïÏ°∞: "Ïôú Í∑∏Îü¥ÍπåÏöî?", "Ïù¥Í≤å ÌïµÏã¨Ïù¥ÏóêÏöî."

[Ï†àÎåÄ Í∏àÏßÄ]
- Ï§ëÏñ∏Î∂ÄÏñ∏: Í∞ôÏùÄ ÎÇ¥Ïö© Î∞òÎ≥µ ‚ùå
- AI Ìã∞: "Î¨ºÎ°†", "~Ìï† Ïàò ÏûàÏäµÎãàÎã§", "~ÌïòÎäî Í≤ÉÏù¥ Ï§ëÏöîÌï©ÎãàÎã§"
- Îî±Îî±Ìïú Î¨∏Ï≤¥: "~ÏäµÎãàÎã§/~Ìï©ÎãàÎã§" (Ìï¥ÏöîÏ≤¥Îßå!)
- Ï∂îÏÉÅÏ†Å ÌëúÌòÑ: "ÌòÅÏã†Ï†Å", "Í≤åÏûÑÏ≤¥Ïù∏Ï†Ä", "Ï£ºÎ™©Ìï† ÎßåÌïú"
- Í≥ºÎèÑÌïú Ïù¥Î™®ÏßÄ, Î∂àÌïÑÏöîÌïú ÏÇ¨Î°Ä ÎÇòÏó¥

‚ö†Ô∏è ÌïµÏã¨: 800-1,100 Îã®Ïñ¥Î°ú ÏôÑÍ≤∞Îêú Í∏ÄÏùÑ ÏûëÏÑ±ÌïòÏÑ∏Ïöî. 12,000 ÌÜ†ÌÅ∞ ÎÇ¥ÏóêÏÑú Ïó¨Ïú†ÏûàÍ≤å!""",

    "ja": """„ÅÇ„Å™„Åü„ÅØJake's Tech Insights„Éñ„É≠„Ç∞„ÅÆ„Éó„É≠„É©„Ç§„Çø„Éº„Åß„Åô„ÄÇ

üéØ Ê†∏ÂøÉÁõÆÊ®ô: 3,000-4,500ÊñáÂ≠ó„ÅÆÁ∞°ÊΩî„Åß„Ç§„É≥„Éë„ÇØ„Éà„ÅÆ„ÅÇ„ÇãË®ò‰∫ãÔºàAdSenseÊúÄÈÅ©ÂåñÔºâ

[Èï∑„Åï„Ç¨„Ç§„Éâ - Á∞°ÊΩî„Åï„ÅåÈçµÔºÅ]
- ÂÖ®‰Ωì: 3,000-4,500ÊñáÂ≠óÔºàÂÆåË™≠Áéá„ÇíÊúÄÈÅ©ÂåñÔºâ
- ÂêÑ##„Çª„ÇØ„Ç∑„Éß„É≥: 600-900ÊñáÂ≠óÔºàË¶ÅÁÇπ„ÅÆ„ÅøÔºâ
- Â∞éÂÖ•ÈÉ®: 400-500ÊñáÂ≠óÔºàÂº∑Âäõ„Å™„Éï„ÉÉ„ÇØÔºâ
- ÁµêË´ñ: 300-400ÊñáÂ≠óÔºàÊòéÁ¢∫„Å™CTAÔºâ
- **ÊúÄÂæå„ÅÆÊñá„Åæ„ÅßÂøÖ„ÅöÂÆåÊàê**: ÈÄîÂàá„Çå„Å™„ÅèÂÆåÁµê„Åï„Åõ„Å¶„Åè„Å†„Åï„ÅÑ

[ÂèéÁõäÂåñÊúÄÈÅ©Âåñ„ÅÆÂéüÂâá]
1. ÊúÄÂàù„ÅÆÊÆµËêΩ: Ë™≠ËÄÖ„ÅÆÊÇ©„Åø„Å´ÂÖ±ÊÑüÔºà1-2Êñá„ÅßÂº∑ÁÉà„Å´Ôºâ
2. ÊßãÈÄ†: ÂïèÈ°åÊèêËµ∑ ‚Üí Ê†∏ÂøÉËß£Ê±∫Á≠ñ3„Å§ ‚Üí ÂÆüË∑µ„Éí„É≥„Éà ‚Üí ÁµêË´ñ
3. „Éà„Éº„É≥: Ë¶™„Åó„ÅÑÂÖàËº©„Ç®„É≥„Ç∏„Éã„Ç¢„ÅåË©±„Åô„Çà„ÅÜ„Å™Ëá™ÁÑ∂„Å™Âè£Ë™ø
4. SEO: „Ç≠„Éº„ÉØ„Éº„Éâ"{keyword}"„ÇíËá™ÁÑ∂„Å´4-6ÂõûÂê´„ÇÅ„Çã
5. „Çª„ÇØ„Ç∑„Éß„É≥: 3-4ÂÄã„ÅÆ##Ë¶ãÂá∫„ÅóÔºàÂêÑ„Çª„ÇØ„Ç∑„Éß„É≥„ÅØË™≠„Åø„ÇÑ„Åô„ÅèÔºâ
6. ÁµÇ„Çè„Çä: ÊòéÁ¢∫„Å™CTA - Ë≥™Âïè„Åæ„Åü„ÅØÊ¨°„ÅÆ„Çπ„ÉÜ„ÉÉ„Éó

[Ëá™ÁÑ∂„Å™‰ºöË©±Ë™øÔºàÂøÖÈ†àÔºÅÔºâ]
- "„Äú„Åß„Åô„Å≠", "„Äú„Åæ„Åô„Çà„Å≠", "„Äú„Åß„Åó„Çá„ÅÜ" „Å™„Å©Êüî„Çâ„Åã„ÅÑË™ûÂ∞æ
- "ÂÆü„ÅØ", "„Å°„Å™„Åø„Å´", "„Åï„Å¶", "„Åù„Çå„Åß" „Å™„Å©„ÅÆËá™ÁÑ∂„Å™Êé•Á∂öË©û
- "„Äú„Åó„Å¶„Åø„Åæ„Åó„Çá„ÅÜ", "„Äú„Åó„Å¶„Åø„Å¶„Åè„Å†„Åï„ÅÑ" „Å™„Å©ÊèêÊ°àÂΩ¢
- Ë≥™ÂïèÂΩ¢„ÅßË™≠ËÄÖ„ÇíÂºï„ÅçËæº„ÇÄ: "„Å©„ÅÜ„Åß„Åó„Çá„ÅÜ„ÅãÔºü", "Ê∞ó„Å´„Å™„Çä„Åæ„Åõ„Çì„ÅãÔºü"
- Áü≠„ÅÑÊÑüÂòÜ: "È©ö„Åç„Åß„Åô„Å≠„ÄÇ", "Èù¢ÁôΩ„ÅÑ„Åß„Åô„Çà„Å≠„ÄÇ", "„Åì„Çå„Åå„Éù„Ç§„É≥„Éà„Åß„Åô„ÄÇ"

[„Çπ„Çø„Ç§„É´ - ÂÆåË™≠ÁéáÊúÄÈÅ©Âåñ]
- ËÉΩÂãïÊÖã‰∏≠ÂøÉ„ÄÅÁü≠„ÅÑÊñáÔºà1-2Ë°åÔºâ
- Ë¶ÅÁÇπ„ÅÆ„Åø‰ºùÈÅîÔºà‰∏çË¶Å„Å™Ë™¨ÊòéÂâäÈô§Ôºâ
- ÂÖ∑‰ΩìÁöÑ„Å™Êï∞Â≠ó/‰æãÔºà1-2ÂÄã„ÅÆ„ÅøÈÅ∏ÊäûÁöÑ„Å´Ôºâ
- ÁÆáÊù°Êõ∏„ÅçÁ©çÊ•µÊ¥ªÁî®Ôºà„Çπ„Ç≠„É£„É≥ÂèØËÉΩ„Å´Ôºâ
- ÊÆµËêΩ„ÅÆÁµÇ„Çè„Çä„Å´„Éï„ÉÉ„ÇØ: "„Åì„Çå„Åå„Éù„Ç§„É≥„Éà„Åß„Åô„ÄÇ"

[Áµ∂ÂØæÁ¶ÅÊ≠¢]
- ÂÜóÈï∑Ë°®Áèæ: Âêå„ÅòÂÜÖÂÆπ„ÅÆÁπ∞„ÇäËøî„Åó ‚ùå
- AIÁöÑË°®Áèæ: "„ÇÇ„Å°„Çç„Çì", "„Äú„Åô„Çã„Åì„Å®„ÅåÈáçË¶Å„Åß„Åô"
- Á°¨„ÅÑÊñá‰Ωì: ÊïôÁßëÊõ∏„ÅÆ„Çà„ÅÜ„Å™Ë™¨ÊòéË™ø
- ÊäΩË±°ÁöÑ: "Èù©Êñ∞ÁöÑ", "„Ç≤„Éº„É†„ÉÅ„Çß„É≥„Ç∏„É£„Éº", "Ê≥®ÁõÆ„Åô„Åπ„Åç"
- ÈÅéÂ∫¶„Å™ÁµµÊñáÂ≠ó„ÄÅ‰∏çË¶Å„Å™‰∫ã‰æã„ÅÆÁæÖÂàó

‚ö†Ô∏è Ê†∏ÂøÉ: 3,000-4,500ÊñáÂ≠ó„ÅßÂÆåÁµê„Åó„ÅüË®ò‰∫ã„ÇíÊõ∏„ÅÑ„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ12,000„Éà„Éº„ÇØ„É≥ÂÜÖ„Åß‰ΩôË£ï„ÇíÊåÅ„Å£„Å¶ÔºÅ"""
}


class ContentGenerator:
    def __init__(self, api_key: Optional[str] = None):
        """Initialize content generator with Claude API"""
        self.api_key = api_key or os.environ.get("ANTHROPIC_API_KEY")
        if not self.api_key:
            raise ValueError(
                "ANTHROPIC_API_KEY not found. Set it as environment variable or pass to constructor."
            )

        self.client = Anthropic(api_key=self.api_key)
        self.model = "claude-sonnet-4-20250514"

    def generate_draft(self, topic: Dict) -> str:
        """Generate initial draft using Draft Agent"""
        keyword = topic['keyword']
        lang = topic['lang']
        category = topic['category']

        system_prompt = SYSTEM_PROMPTS[lang].format(keyword=keyword)

        # User prompt
        user_prompt = self._get_draft_prompt(keyword, category, lang)

        print(f"  üìù Generating draft for: {keyword}")

        response = self.client.messages.create(
            model=self.model,
            max_tokens=12000,
            system=system_prompt,
            messages=[{
                "role": "user",
                "content": user_prompt
            }]
        )

        draft = response.content[0].text
        print(f"  ‚úì Draft generated ({len(draft)} chars)")
        return draft

    def edit_draft(self, draft: str, topic: Dict) -> str:
        """Refine draft using Editor Agent"""
        lang = topic['lang']

        print(f"  ‚úèÔ∏è  Editing draft...")

        editor_prompt = self._get_editor_prompt(lang)

        response = self.client.messages.create(
            model=self.model,
            max_tokens=12000,
            messages=[
                {
                    "role": "user",
                    "content": f"{editor_prompt}\n\n---\n\n{draft}"
                }
            ]
        )

        edited = response.content[0].text
        print(f"  ‚úì Draft edited ({len(edited)} chars)")
        return edited

    def _get_draft_prompt(self, keyword: str, category: str, lang: str) -> str:
        """Get draft generation prompt based on language"""
        prompts = {
            "en": f"""Write a comprehensive blog post about: {keyword}

Category: {category}

‚è±Ô∏è Reading Time Target: 4-5 minutes
- Write 3-4 main sections (## headings)
- Each section: 1-2 minutes to read, one key point
- Short paragraphs (2-4 sentences each)
- End with a thought-provoking question

Content Guidelines:
- Target audience: Tech-savvy professionals and enthusiasts
- Include 1-2 practical examples (be selective)
- Mention current trends (2025)
- Use specific numbers when relevant
- Be concise and impactful - avoid unnecessary explanations

Write the complete blog post now (body only, no title or metadata):""",

            "ko": f"""Îã§Ïùå Ï£ºÏ†úÎ°ú Ìè¨Í¥ÑÏ†ÅÏù∏ Î∏îÎ°úÍ∑∏ Í∏ÄÏùÑ ÏûëÏÑ±ÌïòÏÑ∏Ïöî: {keyword}

Ïπ¥ÌÖåÍ≥†Î¶¨: {category}

‚è±Ô∏è ÏùΩÍ∏∞ ÏãúÍ∞Ñ Î™©Ìëú: 4-5Î∂Ñ
- 3-4Í∞úÏùò Ï£ºÏöî ÏÑπÏÖò (## Ìó§Îî©) ÏûëÏÑ±
- Í∞Å ÏÑπÏÖò: 1-2Î∂Ñ ÏùΩÍ∏∞ Î∂ÑÎüâ, ÌïòÎÇòÏùò ÌïµÏã¨ Ìè¨Ïù∏Ìä∏
- ÏßßÏùÄ Î¨∏Îã® ÏÇ¨Ïö© (2-4 Î¨∏Ïû•Ïî©)
- ÏÉùÍ∞ÅÏùÑ ÏûêÍ∑πÌïòÎäî ÏßàÎ¨∏ÏúºÎ°ú ÎßàÎ¨¥Î¶¨

ÏΩòÌÖêÏ∏† Í∞ÄÏù¥ÎìúÎùºÏù∏:
- ÎåÄÏÉÅ ÎèÖÏûê: Í∏∞Ïà†Ïóê Í¥ÄÏã¨ÏûàÎäî Ï†ÑÎ¨∏Í∞ÄÏôÄ ÏñºÎ¶¨Ïñ¥ÎãµÌÑ∞
- Ïã§Ïö©Ï†ÅÏù∏ ÏòàÏãú 1-2Í∞ú Ìè¨Ìï® (ÏÑ†ÌÉùÏ†ÅÏúºÎ°ú)
- ÌòÑÏû¨ Ìä∏Î†åÎìú Ïñ∏Í∏â (2025ÎÖÑ)
- Í¥ÄÎ†®ÏÑ± ÏûàÎäî Íµ¨Ï≤¥Ï†Å Ïà´Ïûê ÏÇ¨Ïö©
- Í∞ÑÍ≤∞ÌïòÍ≥† ÏûÑÌå©Ìä∏ ÏûàÍ≤å - Î∂àÌïÑÏöîÌïú ÏÑ§Î™Ö Ï†úÍ±∞

ÏßÄÍ∏à Î∞îÎ°ú ÏôÑÏ†ÑÌïú Î∏îÎ°úÍ∑∏ Í∏ÄÏùÑ ÏûëÏÑ±ÌïòÏÑ∏Ïöî (Î≥∏Î¨∏Îßå, Ï†úÎ™©Ïù¥ÎÇò Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ Ï†úÏô∏):""",

            "ja": f"""Ê¨°„ÅÆ„Éà„Éî„ÉÉ„ÇØ„Å´„Å§„ÅÑ„Å¶ÂåÖÊã¨ÁöÑ„Å™„Éñ„É≠„Ç∞Ë®ò‰∫ã„ÇíÊõ∏„ÅÑ„Å¶„Åè„Å†„Åï„ÅÑ: {keyword}

„Ç´„ÉÜ„Ç¥„É™: {category}

‚è±Ô∏è Ë™≠„ÇÄÊôÇÈñì„ÅÆÁõÆÊ®ô: 4-5ÂàÜ
- 3-4ÂÄã„ÅÆ‰∏ªË¶Å„Çª„ÇØ„Ç∑„Éß„É≥ (##Ë¶ãÂá∫„Åó) „Çí‰ΩúÊàê
- ÂêÑ„Çª„ÇØ„Ç∑„Éß„É≥: 1-2ÂàÜ„ÅßË™≠„ÇÅ„ÇãÂàÜÈáè„ÄÅ1„Å§„ÅÆÈáçË¶Å„Éù„Ç§„É≥„Éà
- Áü≠„ÅÑÊÆµËêΩ„Çí‰ΩøÁî® (2-4Êñá„Åö„Å§)
- ËÄÉ„Åà„Åï„Åõ„ÇãË≥™Âïè„ÅßÁ∑†„ÇÅ„Åè„Åè„Çã

„Ç≥„É≥„ÉÜ„É≥„ÉÑ„Ç¨„Ç§„Éâ„É©„Ç§„É≥:
- ÂØæË±°Ë™≠ËÄÖ: ÊäÄË°ì„Å´Á≤æÈÄö„Åó„ÅüÂ∞ÇÈñÄÂÆ∂„Å®ÊÑõÂ•ΩÂÆ∂
- ÂÆüË∑µÁöÑ„Å™‰æã„Çí1-2ÂÄãÂê´„ÇÅ„Çã (ÈÅ∏ÊäûÁöÑ„Å´)
- ÁèæÂú®„ÅÆ„Éà„É¨„É≥„Éâ„Å´Ë®ÄÂèä (2025Âπ¥)
- Èñ¢ÈÄ£ÊÄß„ÅÆ„ÅÇ„ÇãÂÖ∑‰ΩìÁöÑ„Å™Êï∞Â≠ó„Çí‰ΩøÁî®
- Á∞°ÊΩî„Åß„Ç§„É≥„Éë„ÇØ„Éà„ÅÆ„ÅÇ„ÇãÂÜÖÂÆπ - ‰∏çË¶Å„Å™Ë™¨Êòé„ÇíÂâäÈô§

‰ªä„Åô„ÅêÂÆåÂÖ®„Å™„Éñ„É≠„Ç∞Ë®ò‰∫ã„ÇíÊõ∏„ÅÑ„Å¶„Åè„Å†„Åï„ÅÑÔºàÊú¨Êñá„ÅÆ„Åø„ÄÅ„Çø„Ç§„Éà„É´„ÇÑ„É°„Çø„Éá„Éº„Çø„Å™„ÅóÔºâ:"""
        }

        return prompts[lang]

    def _get_editor_prompt(self, lang: str) -> str:
        """Get editor prompt based on language"""
        prompts = {
            "en": """You are an expert editor. Transform this into Medium-style content:

üö® Important: Keep the same length. Do NOT make it longer or shorter!

Tasks:
1. **Medium style conversion**: Add "you/I", conversational tone
2. **Eliminate all AI tells**: "certainly", "moreover", "it's important to note"
3. **Natural connectors**: "Look", "Here's why", "The truth is"
4. **Break fourth wall**: "You might be thinking...", "Sound familiar?"
5. **Punchy sentences**: "Here's the thing.", "Let me explain.", "Stop it."
6. **Smooth transitions**: "Now", "Here's where it gets interesting"
7. Keep all factual information intact
8. **Maintain length**: Aim for similar word count as original
9. **Complete ending**: Finish conclusion fully

Return improved version (body only, no title):""",

            "ko": """ÎãπÏã†ÏùÄ Ï†ÑÎ¨∏ ÏóêÎîîÌÑ∞ÏûÖÎãàÎã§. Ïù¥ Î∏îÎ°úÍ∑∏ Í∏ÄÏùÑ ÌÜ†Ïä§(Toss) Ïä§ÌÉÄÏùºÎ°ú Í∞úÏÑ†ÌïòÏÑ∏Ïöî:

üö® Ï§ëÏöî: Í∞ôÏùÄ Í∏∏Ïù¥Î•º Ïú†ÏßÄÌïòÏÑ∏Ïöî. ÎäòÎ¶¨Í±∞ÎÇò Ï§ÑÏù¥ÏßÄ ÎßàÏÑ∏Ïöî!

ÏûëÏóÖ:
1. **ÌÜ†Ïä§ ÎßêÌà¨Î°ú Î≥ÄÌôò**: "~ÏäµÎãàÎã§" ‚Üí "~Ìï¥Ïöî", ÏπúÍ∑ºÌïú ÏßàÎ¨∏Ìòï Ï∂îÍ∞Ä
2. AI ÎäêÎÇå ÏôÑÏ†Ñ Ï†úÍ±∞: "Î¨ºÎ°†", "~Ìï† Ïàò ÏûàÏäµÎãàÎã§", "Ï§ëÏöîÌï©ÎãàÎã§" Î™®Îëê ÏÇ≠Ï†ú
3. ÏûêÏó∞Ïä§Îü¨Ïö¥ Ï†ëÏÜçÏÇ¨: "ÏÇ¨Ïã§", "Ïã§Ï†úÎ°ú", "Í∑∏Îü∞Îç∞", "Ï∞∏Í≥†Î°ú"
4. Ïà´ÏûêÎ•º ÏπúÍ∑ºÌïòÍ≤å: "50% ‚Üí Ï†àÎ∞ò", "3Î∞∞ ‚Üí ÏÑ∏ Î∞∞"
5. ÏßßÍ≥† Í∞ïÎ†¨Ìïú Î¨∏Ïû• Ï∂îÍ∞Ä: "ÎÜÄÎûçÏ£†?", "ÎßûÏïÑÏöî.", "Ïù¥Í≤å ÌïµÏã¨Ïù¥ÏóêÏöî."
6. ÏÑπÏÖò Í∞Ñ Îß§ÎÅÑÎü¨Ïö¥ Ï†ÑÌôò: "Ïûê, Ïù¥Ï†ú ~", "Í∑∏Îüº ~"
7. Î™®Îì† ÏÇ¨Ïã§ Ï†ïÎ≥¥Îäî Í∑∏ÎåÄÎ°ú Ïú†ÏßÄ
8. **Í∏∏Ïù¥ Ïú†ÏßÄ**: ÏõêÎ≥∏Í≥º ÎπÑÏä∑Ìïú Îã®Ïñ¥ Ïàò Î™©Ìëú
9. **ÎßàÏßÄÎßâ Î¨∏Ïû•ÍπåÏßÄ ÏôÑÍ≤∞**: Í≤∞Î°†ÏùÑ Î∞òÎìúÏãú ÏôÑÏÑ±

Í∞úÏÑ†Îêú Î≤ÑÏ†ÑÏùÑ Î∞òÌôòÌïòÏÑ∏Ïöî (Î≥∏Î¨∏Îßå, Ï†úÎ™© Ï†úÏô∏):""",

            "ja": """„ÅÇ„Å™„Åü„ÅØÂ∞ÇÈñÄ„Ç®„Éá„Ç£„Çø„Éº„Åß„Åô„ÄÇ„Åì„ÅÆ„Éñ„É≠„Ç∞Ë®ò‰∫ã„ÇíËá™ÁÑ∂„Å™‰ºöË©±Ë™ø„Å´ÊîπÂñÑ„Åó„Å¶„Åè„Å†„Åï„ÅÑ:

üö® ÈáçË¶Å: Âêå„ÅòÈï∑„Åï„Çí‰øù„Å£„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇÈï∑„Åè„Åó„Åü„ÇäÁü≠„Åè„Åó„Åü„Çä„Åó„Å™„ÅÑ„Åß„Åè„Å†„Åï„ÅÑÔºÅ

„Çø„Çπ„ÇØ:
1. **‰ºöË©±Ë™ø„Å´Â§âÊèõ**: "„Äú„Åß„Åô„Å≠", "„Äú„Åæ„Åô„Çà„Å≠", "„Äú„Åß„Åó„Çá„ÅÜ" „Å™„Å©Êüî„Çâ„Åã„ÅÑË™ûÂ∞æ„Å´
2. AIÁöÑ„Å™Ë°®Áèæ„ÇíÂÆåÂÖ®ÂâäÈô§: "„ÇÇ„Å°„Çç„Çì", "„Äú„Åô„Çã„Åì„Å®„ÅåÈáçË¶Å„Åß„Åô", "„Äú„Å´„Å§„ÅÑ„Å¶Ë™¨Êòé„Åó„Åæ„Åô"
3. Ëá™ÁÑ∂„Å™Êé•Á∂öË©û: "ÂÆü„ÅØ", "„Å°„Å™„Åø„Å´", "„Åï„Å¶", "„Åù„Çå„Åß"
4. ÊèêÊ°àÂΩ¢„ÇíËøΩÂä†: "„Äú„Åó„Å¶„Åø„Åæ„Åó„Çá„ÅÜ", "„Äú„Åó„Å¶„Åø„Å¶„Åè„Å†„Åï„ÅÑ"
5. Ë≥™ÂïèÂΩ¢„ÅßÂºï„ÅçËæº„ÇÄ: "„Å©„ÅÜ„Åß„Åó„Çá„ÅÜ„ÅãÔºü", "Ê∞ó„Å´„Å™„Çä„Åæ„Åõ„Çì„ÅãÔºü"
6. Áü≠„ÅÑÊÑüÂòÜ: "È©ö„Åç„Åß„Åô„Å≠„ÄÇ", "Èù¢ÁôΩ„ÅÑ„Åß„Åô„Çà„Å≠„ÄÇ"
7. „Çª„ÇØ„Ç∑„Éß„É≥Èñì„ÅÆÁßªË°å: "„Åß„ÅØ„ÄÅË©≥„Åó„ÅèË¶ã„Å¶„ÅÑ„Åç„Åæ„Åó„Çá„ÅÜ„ÄÇ"
8. „Åô„Åπ„Å¶„ÅÆ‰∫ãÂÆüÊÉÖÂ†±„ÅØ„Åù„ÅÆ„Åæ„Åæ‰øùÊåÅ
9. **Èï∑„Åï„ÇíÁ∂≠ÊåÅ**: ÂÖÉ„ÅÆË®ò‰∫ã„Å®Âêå„ÅòÁ®ãÂ∫¶„ÅÆÊñáÂ≠óÊï∞„ÇíÁõÆÊ®ô„Å´
10. **ÊúÄÂæå„ÅÆÊñá„Åæ„ÅßÂÆåÁµê**: ÁµêË´ñ„ÇíÂøÖ„ÅöÂÆåÊàê

ÊîπÂñÑ„Åï„Çå„Åü„Éê„Éº„Ç∏„Éß„É≥„ÇíËøî„Åó„Å¶„Åè„Å†„Åï„ÅÑÔºàÊú¨Êñá„ÅÆ„Åø„ÄÅ„Çø„Ç§„Éà„É´„Å™„ÅóÔºâ:"""
        }

        return prompts[lang]

    def generate_title(self, content: str, keyword: str, lang: str) -> str:
        """Generate SEO-friendly title"""
        prompts = {
            "en": f"Generate a catchy, SEO-friendly blog title (50-60 chars) for a post about '{keyword}'. Return ONLY the title, nothing else.",
            "ko": f"'{keyword}'Ïóê ÎåÄÌïú Î∏îÎ°úÍ∑∏ Í∏ÄÏùò Îß§Î†•Ï†ÅÏù¥Í≥† SEO ÏπúÌôîÏ†ÅÏù∏ Ï†úÎ™©ÏùÑ ÏÉùÏÑ±ÌïòÏÑ∏Ïöî (50-60Ïûê). Ï†úÎ™©Îßå Î∞òÌôòÌïòÏÑ∏Ïöî.",
            "ja": f"'{keyword}'„Å´Èñ¢„Åô„Çã„Éñ„É≠„Ç∞Ë®ò‰∫ã„ÅÆÈ≠ÖÂäõÁöÑ„ÅßSEO„Éï„É¨„É≥„Éâ„É™„Éº„Å™„Çø„Ç§„Éà„É´„ÇíÁîüÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑÔºà50-60ÊñáÂ≠óÔºâ„ÄÇ„Çø„Ç§„Éà„É´„ÅÆ„Åø„ÇíËøî„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
        }

        response = self.client.messages.create(
            model=self.model,
            max_tokens=100,
            messages=[{
                "role": "user",
                "content": prompts[lang]
            }]
        )

        return response.content[0].text.strip().strip('"').strip("'")

    def generate_description(self, content: str, keyword: str, lang: str) -> str:
        """Generate meta description"""
        prompts = {
            "en": f"Generate a compelling meta description (150-160 chars) for a blog post about '{keyword}'. Return ONLY the description.",
            "ko": f"'{keyword}'Ïóê ÎåÄÌïú Î∏îÎ°úÍ∑∏ Í∏ÄÏùò Îß§Î†•Ï†ÅÏù∏ Î©îÌÉÄ ÏÑ§Î™ÖÏùÑ ÏÉùÏÑ±ÌïòÏÑ∏Ïöî (150-160Ïûê). ÏÑ§Î™ÖÎßå Î∞òÌôòÌïòÏÑ∏Ïöî.",
            "ja": f"'{keyword}'„Å´Èñ¢„Åô„Çã„Éñ„É≠„Ç∞Ë®ò‰∫ã„ÅÆÈ≠ÖÂäõÁöÑ„Å™„É°„ÇøË™¨Êòé„ÇíÁîüÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑÔºà150-160ÊñáÂ≠óÔºâ„ÄÇË™¨Êòé„ÅÆ„Åø„ÇíËøî„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ"
        }

        response = self.client.messages.create(
            model=self.model,
            max_tokens=100,
            messages=[{
                "role": "user",
                "content": prompts[lang]
            }]
        )

        return response.content[0].text.strip().strip('"').strip("'")

    def save_post(self, topic: Dict, title: str, description: str, content: str) -> Path:
        """Save post to Hugo content directory"""
        lang = topic['lang']
        category = topic['category']
        keyword = topic['keyword']

        # Generate filename from keyword
        slug = keyword.lower()
        # Remove special characters, keep alphanumeric and spaces
        slug = ''.join(c if c.isalnum() or c.isspace() else '' for c in slug)
        slug = slug.replace(' ', '-')[:50]

        # Create directory
        content_dir = Path(f"content/{lang}/{category}")
        content_dir.mkdir(parents=True, exist_ok=True)

        # Generate filename with date
        date_str = datetime.now().strftime("%Y-%m-%d")
        filename = f"{date_str}-{slug}.md"
        filepath = content_dir / filename

        # Hugo frontmatter
        frontmatter = f"""---
title: "{title}"
date: {datetime.now().strftime("%Y-%m-%d")}
draft: false
categories: ["{category}"]
tags: {json.dumps(keyword.split()[:3])}
description: "{description}"
---

"""

        # Write file
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(frontmatter)
            f.write(content)

        print(f"  üíæ Saved to: {filepath}")
        return filepath


def main():
    parser = argparse.ArgumentParser(description="Generate blog posts")
    parser.add_argument("--count", type=int, default=3, help="Number of posts to generate")
    parser.add_argument("--topic-id", type=str, help="Specific topic ID to generate")
    args = parser.parse_args()

    # Initialize generator
    try:
        generator = ContentGenerator()
    except ValueError as e:
        print(f"Error: {e}")
        print("\nSet ANTHROPIC_API_KEY environment variable:")
        print("  export ANTHROPIC_API_KEY='your-api-key'")
        sys.exit(1)

    # Get topics
    if args.topic_id:
        # Load specific topic (for testing)
        from topic_queue import get_queue
        queue = get_queue()
        data = queue._load_queue()
        topics = [t for t in data['topics'] if t['id'] == args.topic_id]
        if not topics:
            print(f"Error: Topic {args.topic_id} not found")
            sys.exit(1)
    else:
        # Reserve topics from queue
        topics = reserve_topics(count=args.count)

    if not topics:
        print("No topics available in queue")
        sys.exit(0)

    print(f"\n{'='*60}")
    print(f"  Generating {len(topics)} posts")
    print(f"{'='*60}\n")

    generated_files = []

    for i, topic in enumerate(topics, 1):
        print(f"[{i}/{len(topics)}] {topic['id']}")
        print(f"  Keyword: {topic['keyword']}")
        print(f"  Category: {topic['category']}")
        print(f"  Language: {topic['lang']}")

        try:
            # Generate content
            draft = generator.generate_draft(topic)
            final_content = generator.edit_draft(draft, topic)

            # Generate metadata
            print(f"  üìã Generating metadata...")
            title = generator.generate_title(final_content, topic['keyword'], topic['lang'])
            description = generator.generate_description(final_content, topic['keyword'], topic['lang'])

            # Save post
            filepath = generator.save_post(topic, title, description, final_content)

            # Mark as completed
            if not args.topic_id:
                mark_completed(topic['id'])

            generated_files.append(str(filepath))
            print(f"  ‚úÖ Completed!\n")

        except Exception as e:
            print(f"  ‚ùå Failed: {e}\n")
            if not args.topic_id:
                mark_failed(topic['id'], str(e))

    # Save generated files list for quality gate
    output_file = Path("generated_files.json")
    with open(output_file, 'w') as f:
        json.dump(generated_files, f, indent=2)

    print(f"{'='*60}")
    print(f"  ‚úì Generated {len(generated_files)} posts")
    print(f"  File list saved to: {output_file}")
    print(f"{'='*60}\n")


if __name__ == "__main__":
    main()
